{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9\n",
    "The goal of this HW is simple. Duplicate homework 8 problem 2 using neural networks. Contrast regression versus using i.) a neural network with 2 hidden nodes and ii.) 4 hidden nodes over 2 layers with 2 hidden nodes in each layer. All layers should be full connectected, MSE the loss function, a linear output activation layer and RELUs otherwise.\n",
    "\n",
    "You should return an ipynb nothebook with your code and a final table contrasting the different error rates of the different approaches you tried.\n",
    "\n",
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>Y_L1</th>\n",
       "      <th>Y_L2</th>\n",
       "      <th>Y_L3</th>\n",
       "      <th>Y_L4</th>\n",
       "      <th>Y_L5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y  Y_L1  Y_L2  Y_L3  Y_L4  Y_L5\n",
       "0   1.0   4.0   4.0   4.0   5.0   8.0\n",
       "1   4.0   4.0   4.0   5.0   8.0  10.0\n",
       "2   4.0   4.0   5.0   8.0  10.0  12.0\n",
       "3   4.0   5.0   8.0  10.0  12.0  12.0\n",
       "4   5.0   8.0  10.0  12.0  12.0  12.0\n",
       "5   8.0  10.0  12.0  12.0  12.0  12.0\n",
       "6  10.0  12.0  12.0  12.0  12.0  13.0\n",
       "7  12.0  12.0  12.0  12.0  13.0  13.0\n",
       "8  12.0  12.0  12.0  13.0  13.0  14.0\n",
       "9  12.0  12.0  13.0  13.0  14.0  14.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# define the lag function\n",
    "def lag(a, l):    \n",
    "    b1 = a[:-l]\n",
    "    b2 = [np.nan] * l\n",
    "    b = np.concatenate((b2, b1))\n",
    "    return b \n",
    "\n",
    "# Get the country-specific covid case data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "\n",
    "# Country country A, Germany\n",
    "# Select Germany as the picked country A, then remove unnecessary columns\n",
    "df = df.loc[df['Country/Region'] == 'Germany'].reset_index(drop=True)\n",
    "df.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], inplace=True, axis=1)\n",
    "# remove the leading zero\n",
    "df = df.loc[:, (df != 0).all()]\n",
    "# convert to array, and reshape it as one vector\n",
    "arr = np.array(df).reshape((len(df.T),))\n",
    "y_l5 = arr[5:]\n",
    "y_l4 = lag(arr, 1)[5:]\n",
    "y_l3 = lag(arr, 2)[5:]\n",
    "y_l2 = lag(arr, 3)[5:]\n",
    "y_l1 = lag(arr, 4)[5:]\n",
    "y = lag(arr, 5)[5:]\n",
    "# create the new and main dataframe for the regression analysis\n",
    "columns = [\"Y\", \"Y_L1\", \"Y_L2\", \"Y_L3\", \"Y_L4\", \"Y_L5\"]\n",
    "data = np.stack((y, y_l1, y_l2, y_l3, y_l4, y_l5), axis=1)\n",
    "df_A = pd.DataFrame(data=data, columns=columns)\n",
    "df_A.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data \n",
    "### Considering two scenarios; tarining on (1) whole data and (2) half data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([828, 5]) torch.Size([828])\n",
      "torch.Size([414, 5]) torch.Size([414])\n"
     ]
    }
   ],
   "source": [
    "# whole training data\n",
    "X = np.array(df_A[['Y_L1', 'Y_L2', 'Y_L3', 'Y_L4', 'Y_L5']])\n",
    "y = np.array(df_A['Y'])\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.log(torch.from_numpy(y)).float()\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# half training data\n",
    "idx_half = round(len(df_A)/2) # get the index for the half split of X\n",
    "X_half = np.array(df_A[['Y_L1', 'Y_L2', 'Y_L3', 'Y_L4', 'Y_L5']])[:idx_half]\n",
    "y_half = np.array(df_A['Y'])[:idx_half]\n",
    "X_half = torch.from_numpy(X_half).float()\n",
    "y_half = torch.log(torch.from_numpy(y_half)).float()\n",
    "print(X_half.shape, y_half.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.) A neural network with 2 hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([828])) that is different to the input size (torch.Size([828, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.677257921277198e+18\n",
      "1000 6161851.5\n",
      "2000 6161851.5\n",
      "3000 6161851.5\n",
      "4000 6161851.5\n",
      "5000 6161851.5\n",
      "6000 6161851.5\n",
      "7000 6161851.5\n",
      "8000 6161851.5\n",
      "9000 6161851.5\n"
     ]
    }
   ],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 1000, 5, 2, 1\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Run the model on whole data\n",
    "learning_rate = 1e-7\n",
    "for t in range(10000):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 1000 == 0:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "            \n",
    "## try prediction\n",
    "y_pred = model(X)\n",
    "a = y_pred.detach().numpy()\n",
    "\n",
    "#plt.scatter(a[:,0], y_pred[:,0])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1789253.25\n",
      "1000 1789253.25\n",
      "2000 1789253.25\n",
      "3000 1789253.25\n",
      "4000 1789253.25\n",
      "5000 1789253.25\n",
      "6000 1789253.25\n",
      "7000 1789253.25\n",
      "8000 1789253.25\n",
      "9000 1789253.25\n"
     ]
    }
   ],
   "source": [
    "# Run the model on half data\n",
    "learning_rate = 1e-7\n",
    "for t in range(10000):\n",
    "    y_pred = model(X_half)\n",
    "    loss = loss_fn(y_pred, y_half)\n",
    "    if t % 1000 == 0:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "            \n",
    "## try prediction\n",
    "y_pred = model(X)\n",
    "a = y_pred.detach().numpy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii.) 4 hidden nodes over 2 layers with 2 hidden nodes in each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.8067342843904e+16\n",
      "1000 6161851.5\n",
      "2000 6161851.5\n",
      "3000 6161851.5\n",
      "4000 6161851.5\n",
      "5000 6161851.5\n",
      "6000 6161851.5\n",
      "7000 6161851.5\n",
      "8000 6161851.5\n",
      "9000 6161851.5\n"
     ]
    }
   ],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H1 is hidden layer 1 dimension; H2 is hidden layer 2 dimension; \n",
    "# D_out is output dimension.\n",
    "N, D_in, H1, H2, D_out = 1000, 5, 2, 2, 1\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H1, H2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H2, D_out),\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Run the model on whole data\n",
    "learning_rate = 1e-7\n",
    "for t in range(10000):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 1000 == 0:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "            \n",
    "## try prediction\n",
    "y_pred = model(X)\n",
    "a = y_pred.detach().numpy()\n",
    "\n",
    "#plt.scatter(a[:,0], y_pred[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2398440.25\n",
      "1000 1789253.25\n",
      "2000 1789253.25\n",
      "3000 1789253.25\n",
      "4000 1789253.25\n",
      "5000 1789253.25\n",
      "6000 1789253.25\n",
      "7000 1789253.25\n",
      "8000 1789253.25\n",
      "9000 1789253.25\n"
     ]
    }
   ],
   "source": [
    "# Run the model on half data\n",
    "learning_rate = 1e-7\n",
    "for t in range(10000):\n",
    "    y_pred = model(X_half)\n",
    "    loss = loss_fn(y_pred, y_half)\n",
    "    if t % 1000 == 0:\n",
    "        print(t, loss.item())\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "            \n",
    "## try prediction\n",
    "y_pred = model(X)\n",
    "a = y_pred.detach().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
